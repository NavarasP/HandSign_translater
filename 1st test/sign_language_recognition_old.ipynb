{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Recognition with RNN\n",
    "\n",
    "This notebook trains an RNN model to recognize sign language from landmark data extracted using MediaPipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(gpu)\n",
    "    except RuntimeError as e:\n",
    "        print('error'+ e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x0000021BCE329990 to Device at 0x0000021BCE30C6D0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_words = [\"TV\", \"after\", \"airplane\", \"all\", \"alligator\", \"animal\", \"another\", \"any\", \"apple\", \"arm\"]\n",
    "selected_words = [\"TV\", \"after\", \"airplane\", \"all\", \"alligator\"]\n",
    "\n",
    "# Filter the dataframe to include only the selected words\n",
    "filtered_df = train_df[train_df['sign'].isin(selected_words)]\n",
    "\n",
    "# Group by 'sign' and select 10 sequences for each word\n",
    "subset_df = filtered_df.groupby('sign').head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>train_landmark_files/61333/1002052130.parquet</td>\n",
       "      <td>61333</td>\n",
       "      <td>1002052130</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>train_landmark_files/62590/1002885072.parquet</td>\n",
       "      <td>62590</td>\n",
       "      <td>1002885072</td>\n",
       "      <td>alligator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>train_landmark_files/22343/1003347075.parquet</td>\n",
       "      <td>22343</td>\n",
       "      <td>1003347075</td>\n",
       "      <td>TV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>train_landmark_files/32319/1007376023.parquet</td>\n",
       "      <td>32319</td>\n",
       "      <td>1007376023</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>train_landmark_files/61333/1007883975.parquet</td>\n",
       "      <td>61333</td>\n",
       "      <td>1007883975</td>\n",
       "      <td>alligator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53564</th>\n",
       "      <td>train_landmark_files/55372/3192381381.parquet</td>\n",
       "      <td>55372</td>\n",
       "      <td>3192381381</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53686</th>\n",
       "      <td>train_landmark_files/49445/319779922.parquet</td>\n",
       "      <td>49445</td>\n",
       "      <td>319779922</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54446</th>\n",
       "      <td>train_landmark_files/53618/3226528685.parquet</td>\n",
       "      <td>53618</td>\n",
       "      <td>3226528685</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54901</th>\n",
       "      <td>train_landmark_files/32319/324454876.parquet</td>\n",
       "      <td>32319</td>\n",
       "      <td>324454876</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55213</th>\n",
       "      <td>train_landmark_files/34503/3257700521.parquet</td>\n",
       "      <td>34503</td>\n",
       "      <td>3257700521</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  participant_id  \\\n",
       "50     train_landmark_files/61333/1002052130.parquet           61333   \n",
       "73     train_landmark_files/62590/1002885072.parquet           62590   \n",
       "84     train_landmark_files/22343/1003347075.parquet           22343   \n",
       "187    train_landmark_files/32319/1007376023.parquet           32319   \n",
       "197    train_landmark_files/61333/1007883975.parquet           61333   \n",
       "...                                              ...             ...   \n",
       "53564  train_landmark_files/55372/3192381381.parquet           55372   \n",
       "53686   train_landmark_files/49445/319779922.parquet           49445   \n",
       "54446  train_landmark_files/53618/3226528685.parquet           53618   \n",
       "54901   train_landmark_files/32319/324454876.parquet           32319   \n",
       "55213  train_landmark_files/34503/3257700521.parquet           34503   \n",
       "\n",
       "       sequence_id       sign  \n",
       "50      1002052130         TV  \n",
       "73      1002885072  alligator  \n",
       "84      1003347075         TV  \n",
       "187     1007376023        all  \n",
       "197     1007883975  alligator  \n",
       "...            ...        ...  \n",
       "53564   3192381381      after  \n",
       "53686    319779922      after  \n",
       "54446   3226528685      after  \n",
       "54901    324454876      after  \n",
       "55213   3257700521      after  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1000 entries, 50 to 55213\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   path            1000 non-null   object\n",
      " 1   participant_id  1000 non-null   int64 \n",
      " 2   sequence_id     1000 non-null   int64 \n",
      " 3   sign            1000 non-null   object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 39.1+ KB\n"
     ]
    }
   ],
   "source": [
    "subset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load parquet files\n",
    "def load_parquet_file(filepath):\n",
    "    df = pd.read_parquet(filepath)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(subset_df):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    for index, row in subset_df.iterrows():\n",
    "        path = row['path']\n",
    "        label = row['sign']\n",
    "        \n",
    "        # Load the landmark file\n",
    "        landmark_df = load_parquet_file(path)\n",
    "        \n",
    "        # Extract x, y coordinates\n",
    "        face = landmark_df[landmark_df['type'] == 'face'][['x', 'y']].values\n",
    "        left_hand = landmark_df[landmark_df['type'] == 'left_hand'][['x', 'y']].values\n",
    "        pose = landmark_df[landmark_df['type'] == 'pose'][['x', 'y']].values\n",
    "        right_hand = landmark_df[landmark_df['type'] == 'right_hand'][['x', 'y']].values\n",
    "        \n",
    "        # Ensure the landmarks have consistent lengths\n",
    "        # max_landmarks = max(len(face), len(left_hand), len(pose), len(right_hand))\n",
    "        face = np.pad(face, ((0, 468 - len(face)), (0, 0)), mode='constant')\n",
    "        left_hand = np.pad(left_hand, ((0, 21 - len(left_hand)), (0, 0)), mode='constant')\n",
    "        pose = np.pad(pose, ((0, 33 - len(pose)), (0, 0)), mode='constant')\n",
    "        right_hand = np.pad(right_hand, ((0, 21 - len(right_hand)), (0, 0)), mode='constant')\n",
    "        \n",
    "        # Concatenate the landmarks\n",
    "        sequence = np.concatenate([face, left_hand, pose, right_hand], axis=0)\n",
    "        \n",
    "        sequences.append(sequence)\n",
    "        labels.append(label)\n",
    "    \n",
    "    # Calculate the maximum sequence length\n",
    "    \n",
    "    # Pad the sequences to ensure they all have the same length\n",
    "    max_sequence_length = 500  # Set a maximum sequence length\n",
    "    sequences_padded = pad_sequences(sequences, maxlen=max_sequence_length, padding='post', dtype='float32')\n",
    "    \n",
    "    # Label encoding\n",
    "    label_encoder = LabelEncoder()\n",
    "    labels_encoded = label_encoder.fit_transform(labels)\n",
    "    joblib.dump(label_encoder, 'label_encoder.pkl')\n",
    "    \n",
    "    return sequences_padded, labels_encoded, max_sequence_length, label_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "index can't contain negative values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sequences_padded, labels_encoded, max_seq_len, label_encoder \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 20\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(subset_df)\u001b[0m\n\u001b[0;32m     16\u001b[0m right_hand \u001b[38;5;241m=\u001b[39m landmark_df[landmark_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright_hand\u001b[39m\u001b[38;5;124m'\u001b[39m][[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Ensure the landmarks have consistent lengths\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# max_landmarks = max(len(face), len(left_hand), len(pose), len(right_hand))\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m face \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mface\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m468\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mface\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m left_hand \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(left_hand, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m21\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(left_hand)), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m pose \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(pose, ((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m33\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(pose)), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Projects\\AIML\\HandSign\\env\\lib\\site-packages\\numpy\\lib\\arraypad.py:748\u001b[0m, in \u001b[0;36mpad\u001b[1;34m(array, pad_width, mode, **kwargs)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`pad_width` must be of integral type.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Broadcast to shape (array.ndim, 2)\u001b[39;00m\n\u001b[1;32m--> 748\u001b[0m pad_width \u001b[38;5;241m=\u001b[39m \u001b[43m_as_pairs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpad_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(mode):\n\u001b[0;32m    751\u001b[0m     \u001b[38;5;66;03m# Old behavior: Use user-supplied function with np.apply_along_axis\u001b[39;00m\n\u001b[0;32m    752\u001b[0m     function \u001b[38;5;241m=\u001b[39m mode\n",
      "File \u001b[1;32md:\\Projects\\AIML\\HandSign\\env\\lib\\site-packages\\numpy\\lib\\arraypad.py:518\u001b[0m, in \u001b[0;36m_as_pairs\u001b[1;34m(x, ndim, as_index)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ((x[\u001b[38;5;241m0\u001b[39m], x[\u001b[38;5;241m1\u001b[39m]),) \u001b[38;5;241m*\u001b[39m ndim\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_index \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 518\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt contain negative values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    520\u001b[0m \u001b[38;5;66;03m# Converting the array with `tolist` seems to improve performance\u001b[39;00m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;66;03m# when iterating and indexing the result (see usage in `pad`)\u001b[39;00m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mbroadcast_to(x, (ndim, \u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mValueError\u001b[0m: index can't contain negative values"
     ]
    }
   ],
   "source": [
    "sequences_padded, labels_encoded, max_seq_len, label_encoder = preprocess_data(subset_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Masking layer for handling variable sequence lengths\n",
    "model.add(Masking(mask_value=0., input_shape=(max_seq_len, sequences_padded.shape[2])))\n",
    "\n",
    "# LSTM layers with dropout for regularization\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.3))  # Dropout layer to prevent overfitting\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# Dense output layer with softmax activation for multi-class classification\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model with Adam optimizer and categorical cross-entropy loss\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Print model summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Masking(mask_value=0., input_shape=(max_seq_len, sequences_padded.shape[2])))  # Adjust input shape based on sequence length and number of features\n",
    "# model.add(LSTM(128, return_sequences=True))\n",
    "# model.add(LSTM(128))\n",
    "# model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " masking (Masking)           (None, 500, 2)            0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 500, 256)          265216    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 500, 256)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 256)               525312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 791,813\n",
      "Trainable params: 791,813\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "225/225 [==============================] - 367s 2s/step - loss: 1.6098 - accuracy: 0.1800 - val_loss: 1.6113 - val_accuracy: 0.1600\n",
      "Epoch 2/20\n",
      "225/225 [==============================] - 349s 2s/step - loss: 1.6097 - accuracy: 0.1878 - val_loss: 1.6133 - val_accuracy: 0.1600\n",
      "Epoch 3/20\n",
      "225/225 [==============================] - 357s 2s/step - loss: 1.6094 - accuracy: 0.1833 - val_loss: 1.6153 - val_accuracy: 0.1600\n",
      "Epoch 4/20\n",
      "225/225 [==============================] - 352s 2s/step - loss: 1.6095 - accuracy: 0.1978 - val_loss: 1.6161 - val_accuracy: 0.1600\n",
      "Epoch 5/20\n",
      "225/225 [==============================] - 348s 2s/step - loss: 1.6093 - accuracy: 0.2000 - val_loss: 1.6174 - val_accuracy: 0.1600\n",
      "Epoch 6/20\n",
      "225/225 [==============================] - 356s 2s/step - loss: 1.6094 - accuracy: 0.1722 - val_loss: 1.6192 - val_accuracy: 0.1600\n",
      "Epoch 7/20\n",
      "225/225 [==============================] - 354s 2s/step - loss: 1.6093 - accuracy: 0.1844 - val_loss: 1.6193 - val_accuracy: 0.1600\n",
      "Epoch 8/20\n",
      "225/225 [==============================] - 361s 2s/step - loss: 1.6092 - accuracy: 0.1967 - val_loss: 1.6193 - val_accuracy: 0.1600\n",
      "Epoch 9/20\n",
      "225/225 [==============================] - 354s 2s/step - loss: 1.6093 - accuracy: 0.1856 - val_loss: 1.6199 - val_accuracy: 0.1600\n",
      "Epoch 10/20\n",
      "225/225 [==============================] - 350s 2s/step - loss: 1.6092 - accuracy: 0.1744 - val_loss: 1.6213 - val_accuracy: 0.1600\n",
      "Epoch 11/20\n",
      "225/225 [==============================] - 352s 2s/step - loss: 1.6092 - accuracy: 0.1933 - val_loss: 1.6217 - val_accuracy: 0.1600\n",
      "Epoch 12/20\n",
      "225/225 [==============================] - 357s 2s/step - loss: 1.6092 - accuracy: 0.1856 - val_loss: 1.6215 - val_accuracy: 0.1600\n",
      "Epoch 13/20\n",
      "225/225 [==============================] - 351s 2s/step - loss: 1.6091 - accuracy: 0.1922 - val_loss: 1.6217 - val_accuracy: 0.1600\n",
      "Epoch 14/20\n",
      "225/225 [==============================] - 384s 2s/step - loss: 1.6092 - accuracy: 0.1944 - val_loss: 1.6224 - val_accuracy: 0.1600\n",
      "Epoch 15/20\n",
      "225/225 [==============================] - 382s 2s/step - loss: 1.6092 - accuracy: 0.1967 - val_loss: 1.6218 - val_accuracy: 0.1600\n",
      "Epoch 16/20\n",
      "225/225 [==============================] - 365s 2s/step - loss: 1.6093 - accuracy: 0.1900 - val_loss: 1.6219 - val_accuracy: 0.1600\n",
      "Epoch 17/20\n",
      "225/225 [==============================] - 386s 2s/step - loss: 1.6092 - accuracy: 0.1956 - val_loss: 1.6220 - val_accuracy: 0.1600\n",
      "Epoch 18/20\n",
      "225/225 [==============================] - 354s 2s/step - loss: 1.6092 - accuracy: 0.2044 - val_loss: 1.6222 - val_accuracy: 0.1600\n",
      "Epoch 19/20\n",
      "225/225 [==============================] - 333s 1s/step - loss: 1.6091 - accuracy: 0.2033 - val_loss: 1.6222 - val_accuracy: 0.1600\n",
      "Epoch 20/20\n",
      "225/225 [==============================] - 354s 2s/step - loss: 1.6092 - accuracy: 0.1833 - val_loss: 1.6227 - val_accuracy: 0.1600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1465f974040>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_padded, labels_encoded, epochs=20, batch_size=4, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 16s 371ms/step - loss: 1.6102 - accuracy: 0.2000\n",
      "Loss: 1.6101627349853516, Accuracy: 0.20000000298023224\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(sequences_padded, labels_encoded)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "type(sequences_padded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TensorFlow Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Convert the model to TensorFlow Lite format\n",
    "# converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# # Save the model\n",
    "# with open('model.tflite', 'wb') as f:\n",
    "#     f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
