{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System Configration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(gpu)\n",
    "    except RuntimeError as e:\n",
    "        print('error'+ e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weakproxy at 0x0000029C31DEEB10 to Device at 0x0000029C77B20550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda.select_device(0)\n",
    "cuda.close()\n",
    "cuda.select_device(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sign Language Recognition with RNN\n",
    "\n",
    "This notebook trains an RNN model to recognize sign language from landmark data extracted using MediaPipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the combined CSV file into a DataFrame\n",
    "# csv_file_path = 'D:/Projects/AIML/HandSign/Dataset_CSVs/transformed_data.csv'\n",
    "csv_file_path = 'D:/Projects/AIML/HandSign/Dataset_CSVs/keypoints_data.csv'\n",
    "\n",
    "df = pd.read_csv(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   face_0_x  face_0_y  face_1_x  face_1_y  face_2_x  face_2_y  face_3_x  \\\n",
      "0  0.480987  0.600960  0.486844  0.549152  0.483475  0.566798  0.479284   \n",
      "1  0.515435  0.612552  0.521321  0.560277  0.517003  0.578228  0.511478   \n",
      "2  0.499053  0.592653  0.503803  0.538680  0.500637  0.558055  0.494142   \n",
      "3  0.437985  0.589782  0.439237  0.538740  0.438284  0.556461  0.429700   \n",
      "4  0.420540  0.584587  0.419919  0.535113  0.419445  0.551029  0.408256   \n",
      "\n",
      "   face_3_y  face_4_x  face_4_y  ...  pose_28_y  pose_29_x  pose_29_y  \\\n",
      "0  0.495447  0.488247  0.532376  ...   3.211675   0.699006   3.337574   \n",
      "1  0.506666  0.522563  0.543482  ...   3.176484   0.687595   3.314011   \n",
      "2  0.487191  0.504793  0.522018  ...   3.123261   0.685968   3.249211   \n",
      "3  0.488853  0.439693  0.522769  ...   3.069936   0.615897   3.201243   \n",
      "4  0.484223  0.419772  0.519081  ...   3.183950   0.663719   3.308161   \n",
      "\n",
      "   pose_30_x  pose_30_y  pose_31_x  pose_31_y  pose_32_x  pose_32_y  label  \n",
      "0   0.386315   3.310355   0.652768   3.440469   0.438355   3.428981      A  \n",
      "1   0.347050   3.274199   0.615969   3.411350   0.400396   3.408218      A  \n",
      "2   0.402161   3.224098   0.647203   3.359931   0.446049   3.337926      A  \n",
      "3   0.283825   3.157427   0.545426   3.312458   0.328650   3.307702      A  \n",
      "4   0.319413   3.274222   0.582834   3.420210   0.364315   3.421397      A  \n",
      "\n",
      "[5 rows x 1087 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 175 entries, 0 to 174\n",
      "Columns: 1087 entries, face_0_x to label\n",
      "dtypes: float64(1086), object(1)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 1087)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_hand_columns = [col for col in df.columns if col.startswith('left_hand')]\n",
    "right_hand_columns = [col for col in df.columns if col.startswith('right_hand')]\n",
    "pose_columns = [col for col in df.columns if col.startswith('pose')]\n",
    "\n",
    "# Ensure the data is in the correct shape (number_of_samples, number_of_frames, number_of_features_per_frame)\n",
    "def reshape_data(df, columns, num_frames):\n",
    "    data = df[columns].values\n",
    "    num_samples = len(df) // num_frames\n",
    "    data = data.reshape(num_samples, num_frames, len(columns))\n",
    "    return data\n",
    "\n",
    "\n",
    "# Assuming num_frames is known\n",
    "num_frames = 1 # This should be the length of the time series\n",
    "\n",
    "left_hand_data = reshape_data(df, left_hand_columns, num_frames)\n",
    "right_hand_data = reshape_data(df, right_hand_columns, num_frames)\n",
    "pose_data = reshape_data(df, pose_columns, num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left hand data shape: (175, 1, 42)\n",
      "Right hand data shape: (175, 1, 42)\n",
      "Pose data shape: (175, 1, 66)\n"
     ]
    }
   ],
   "source": [
    "print(\"Left hand data shape:\", left_hand_data.shape)\n",
    "print(\"Right hand data shape:\", right_hand_data.shape)\n",
    "print(\"Pose data shape:\", pose_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the labels and convert them to one-hot encoding if necessary\n",
    "labels = df['label'].values[:len(df) // num_frames * num_frames]\n",
    "labels = labels.reshape(len(labels) // num_frames, num_frames)[:, 0]  # Assuming one label per sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "labels_onehot = onehot_encoder.fit_transform(labels_encoded.reshape(-1, 1))\n",
    "\n",
    "\n",
    "# with open('Models/label_encoder_word.pkl', 'wb') as file:\n",
    "#     pickle.dump(label_encoder, file)\n",
    "\n",
    "with open('Models/label_encoder_letter.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define input shapes for each branch\n",
    "hand_input_shape = (num_frames, len(right_hand_columns))\n",
    "pose_input_shape = (num_frames, len(pose_columns))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Multiply\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_multi_branch_model(hand_input_shape, pose_input_shape, number_of_classes, hand_units=50, pose_units=25):\n",
    "    \n",
    "    # Input layers for each set of features\n",
    "    left_hand_input = Input(shape=hand_input_shape)\n",
    "    right_hand_input = Input(shape=hand_input_shape)\n",
    "    pose_input = Input(shape=pose_input_shape)\n",
    "    \n",
    "    \n",
    "    # Left Hand branch\n",
    "    left_hand_lstm = LSTM(units=hand_units)(left_hand_input)\n",
    "    \n",
    "    # Right Hand branch\n",
    "    right_hand_lstm = LSTM(units=hand_units)(right_hand_input)\n",
    "    \n",
    "    # Pose branch\n",
    "    pose_lstm = LSTM(units=pose_units)(pose_input)\n",
    "    \n",
    "    \n",
    "    # Weighted combination of branches\n",
    "    left_hand_output = Multiply()([left_hand_lstm, Dense(1, activation='linear', use_bias=False)(left_hand_lstm)])\n",
    "    right_hand_output = Multiply()([right_hand_lstm, Dense(1, activation='linear', use_bias=False)(right_hand_lstm)])\n",
    "    pose_output = Multiply()([pose_lstm, Dense(1, activation='linear', use_bias=False)(pose_lstm)])\n",
    "    \n",
    "    # Concatenate the outputs\n",
    "    combined_output = Concatenate()([left_hand_output, right_hand_output, pose_output])\n",
    "    \n",
    "    # Final dense layer for classification\n",
    "    final_output = Dense(units=number_of_classes, activation='softmax')(combined_output)\n",
    "    \n",
    "    model = Model(inputs=[left_hand_input, right_hand_input, pose_input], outputs=final_output)\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = len(onehot_encoder.categories_[0])\n",
    "model = create_multi_branch_model(hand_input_shape, pose_input_shape,  number_of_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "X_left_train, X_left_val, X_right_train, X_right_val, X_pose_train, X_pose_val, y_train, y_val = train_test_split(\n",
    "    left_hand_data, right_hand_data, pose_data, labels_onehot, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5/5 [==============================] - 36s 561ms/step - loss: 3.2570 - accuracy: 0.0571 - val_loss: 3.2801 - val_accuracy: 0.0286\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 3.2482 - accuracy: 0.0571 - val_loss: 3.2820 - val_accuracy: 0.0286\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 63ms/step - loss: 3.2396 - accuracy: 0.0571 - val_loss: 3.2947 - val_accuracy: 0.0286\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 3.2218 - accuracy: 0.0571 - val_loss: 3.3197 - val_accuracy: 0.0286\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 3.1981 - accuracy: 0.0571 - val_loss: 3.3660 - val_accuracy: 0.0286\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 3.1646 - accuracy: 0.0571 - val_loss: 3.4268 - val_accuracy: 0.0286\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 3.1290 - accuracy: 0.0786 - val_loss: 3.4910 - val_accuracy: 0.0571\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 3.0857 - accuracy: 0.1000 - val_loss: 3.5147 - val_accuracy: 0.0286\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 3.0373 - accuracy: 0.1286 - val_loss: 3.5138 - val_accuracy: 0.0286\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 2.9988 - accuracy: 0.1500 - val_loss: 3.5380 - val_accuracy: 0.0286\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2.9602 - accuracy: 0.1500 - val_loss: 3.5453 - val_accuracy: 0.0286\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 2.9224 - accuracy: 0.1429 - val_loss: 3.5238 - val_accuracy: 0.0571\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 2.8828 - accuracy: 0.2071 - val_loss: 3.4863 - val_accuracy: 0.0571\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 71ms/step - loss: 2.8302 - accuracy: 0.2143 - val_loss: 3.4180 - val_accuracy: 0.0571\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 69ms/step - loss: 2.7862 - accuracy: 0.2286 - val_loss: 3.3508 - val_accuracy: 0.0857\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 85ms/step - loss: 2.7368 - accuracy: 0.2429 - val_loss: 3.2985 - val_accuracy: 0.0571\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 80ms/step - loss: 2.6777 - accuracy: 0.2071 - val_loss: 3.2642 - val_accuracy: 0.0857\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 75ms/step - loss: 2.6252 - accuracy: 0.2286 - val_loss: 3.2006 - val_accuracy: 0.1143\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 2.5799 - accuracy: 0.2214 - val_loss: 3.1832 - val_accuracy: 0.0857\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 72ms/step - loss: 2.5319 - accuracy: 0.2357 - val_loss: 3.1233 - val_accuracy: 0.1143\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 86ms/step - loss: 2.4913 - accuracy: 0.2214 - val_loss: 3.0417 - val_accuracy: 0.1143\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 64ms/step - loss: 2.4360 - accuracy: 0.2286 - val_loss: 2.9894 - val_accuracy: 0.1429\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 2.3981 - accuracy: 0.2429 - val_loss: 2.9855 - val_accuracy: 0.1429\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 2.3463 - accuracy: 0.2786 - val_loss: 2.8777 - val_accuracy: 0.1143\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 2.2980 - accuracy: 0.3357 - val_loss: 2.8058 - val_accuracy: 0.1714\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 2.2402 - accuracy: 0.3571 - val_loss: 2.7527 - val_accuracy: 0.2000\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 2.1998 - accuracy: 0.3143 - val_loss: 2.6598 - val_accuracy: 0.1429\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 2.1424 - accuracy: 0.3714 - val_loss: 2.5419 - val_accuracy: 0.2000\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 2.0920 - accuracy: 0.4357 - val_loss: 2.4698 - val_accuracy: 0.2286\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 2.0446 - accuracy: 0.4143 - val_loss: 2.4312 - val_accuracy: 0.3143\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.9841 - accuracy: 0.4500 - val_loss: 2.4174 - val_accuracy: 0.2000\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 1.9382 - accuracy: 0.4286 - val_loss: 2.3340 - val_accuracy: 0.2571\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 1.8893 - accuracy: 0.5143 - val_loss: 2.2336 - val_accuracy: 0.2857\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.8483 - accuracy: 0.4714 - val_loss: 2.2705 - val_accuracy: 0.2000\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 1.7788 - accuracy: 0.5143 - val_loss: 2.1658 - val_accuracy: 0.2857\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.7515 - accuracy: 0.5286 - val_loss: 2.1109 - val_accuracy: 0.2857\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 1.6997 - accuracy: 0.4714 - val_loss: 2.1048 - val_accuracy: 0.3429\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.6272 - accuracy: 0.5000 - val_loss: 1.9008 - val_accuracy: 0.5429\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.5864 - accuracy: 0.6000 - val_loss: 1.7649 - val_accuracy: 0.6286\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 1.5426 - accuracy: 0.6357 - val_loss: 1.8015 - val_accuracy: 0.6286\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 1.5080 - accuracy: 0.5786 - val_loss: 2.0285 - val_accuracy: 0.2857\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 1.4598 - accuracy: 0.5143 - val_loss: 1.8829 - val_accuracy: 0.3429\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 1.4098 - accuracy: 0.6071 - val_loss: 1.7123 - val_accuracy: 0.5143\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 1.3577 - accuracy: 0.6429 - val_loss: 1.6668 - val_accuracy: 0.6571\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 1.3288 - accuracy: 0.7000 - val_loss: 1.6751 - val_accuracy: 0.6571\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.2856 - accuracy: 0.6714 - val_loss: 1.6327 - val_accuracy: 0.5714\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.2518 - accuracy: 0.6643 - val_loss: 1.5685 - val_accuracy: 0.4571\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 1.2247 - accuracy: 0.6714 - val_loss: 1.4385 - val_accuracy: 0.6571\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 1.2126 - accuracy: 0.7000 - val_loss: 1.4871 - val_accuracy: 0.6000\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 1.1622 - accuracy: 0.6857 - val_loss: 1.4255 - val_accuracy: 0.6857\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 1.1477 - accuracy: 0.6500 - val_loss: 1.3815 - val_accuracy: 0.6857\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.1225 - accuracy: 0.7143 - val_loss: 1.4553 - val_accuracy: 0.6286\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 1.0806 - accuracy: 0.6857 - val_loss: 1.3855 - val_accuracy: 0.7429\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 1.0606 - accuracy: 0.7071 - val_loss: 1.3738 - val_accuracy: 0.6571\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 1.0429 - accuracy: 0.7071 - val_loss: 1.3961 - val_accuracy: 0.6286\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 1.0184 - accuracy: 0.7286 - val_loss: 1.3276 - val_accuracy: 0.6571\n",
      "Epoch 57/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.9933 - accuracy: 0.7286 - val_loss: 1.2730 - val_accuracy: 0.6857\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.9636 - accuracy: 0.7357 - val_loss: 1.3278 - val_accuracy: 0.6857\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.9600 - accuracy: 0.7429 - val_loss: 1.2630 - val_accuracy: 0.7143\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.9234 - accuracy: 0.7643 - val_loss: 1.1998 - val_accuracy: 0.7143\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.9346 - accuracy: 0.7429 - val_loss: 1.2495 - val_accuracy: 0.7429\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8988 - accuracy: 0.7714 - val_loss: 1.1630 - val_accuracy: 0.7429\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8964 - accuracy: 0.7500 - val_loss: 1.1788 - val_accuracy: 0.7143\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.8757 - accuracy: 0.7857 - val_loss: 1.1820 - val_accuracy: 0.7714\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.8432 - accuracy: 0.7786 - val_loss: 1.1777 - val_accuracy: 0.7714\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.8380 - accuracy: 0.7714 - val_loss: 1.1617 - val_accuracy: 0.7714\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.8154 - accuracy: 0.7929 - val_loss: 1.1406 - val_accuracy: 0.6857\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.8041 - accuracy: 0.7929 - val_loss: 1.1681 - val_accuracy: 0.7429\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.7886 - accuracy: 0.8000 - val_loss: 1.1405 - val_accuracy: 0.7714\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.7803 - accuracy: 0.7929 - val_loss: 1.1835 - val_accuracy: 0.7714\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.7652 - accuracy: 0.7857 - val_loss: 1.0984 - val_accuracy: 0.7429\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7549 - accuracy: 0.8214 - val_loss: 1.1105 - val_accuracy: 0.7143\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.7580 - accuracy: 0.8071 - val_loss: 1.1010 - val_accuracy: 0.7143\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7351 - accuracy: 0.8429 - val_loss: 1.1534 - val_accuracy: 0.7143\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.7331 - accuracy: 0.8071 - val_loss: 1.1452 - val_accuracy: 0.7429\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.7369 - accuracy: 0.7929 - val_loss: 1.1367 - val_accuracy: 0.7429\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.7306 - accuracy: 0.7786 - val_loss: 1.0689 - val_accuracy: 0.7143\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.7106 - accuracy: 0.8071 - val_loss: 1.0329 - val_accuracy: 0.7429\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.6912 - accuracy: 0.8357 - val_loss: 1.0706 - val_accuracy: 0.7143\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6818 - accuracy: 0.8071 - val_loss: 1.0979 - val_accuracy: 0.7429\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6781 - accuracy: 0.7929 - val_loss: 1.0886 - val_accuracy: 0.7429\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.6701 - accuracy: 0.8214 - val_loss: 1.0694 - val_accuracy: 0.7429\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.6599 - accuracy: 0.8286 - val_loss: 1.1267 - val_accuracy: 0.7429\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.6445 - accuracy: 0.8357 - val_loss: 1.1351 - val_accuracy: 0.7143\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.6405 - accuracy: 0.8071 - val_loss: 1.1437 - val_accuracy: 0.7429\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6453 - accuracy: 0.8214 - val_loss: 1.1031 - val_accuracy: 0.7429\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.6273 - accuracy: 0.8357 - val_loss: 1.0779 - val_accuracy: 0.7429\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6278 - accuracy: 0.8357 - val_loss: 1.0651 - val_accuracy: 0.7714\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6189 - accuracy: 0.8429 - val_loss: 1.0754 - val_accuracy: 0.8000\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.6099 - accuracy: 0.8214 - val_loss: 1.0871 - val_accuracy: 0.7714\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.6111 - accuracy: 0.8429 - val_loss: 1.0727 - val_accuracy: 0.7429\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.6034 - accuracy: 0.8571 - val_loss: 1.1052 - val_accuracy: 0.7429\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.5884 - accuracy: 0.8571 - val_loss: 1.1185 - val_accuracy: 0.7429\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.6115 - accuracy: 0.8071 - val_loss: 1.1508 - val_accuracy: 0.7429\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5809 - accuracy: 0.8286 - val_loss: 1.1149 - val_accuracy: 0.7714\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5791 - accuracy: 0.8214 - val_loss: 1.1106 - val_accuracy: 0.7429\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5814 - accuracy: 0.8357 - val_loss: 1.1388 - val_accuracy: 0.7143\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.5771 - accuracy: 0.8071 - val_loss: 1.0406 - val_accuracy: 0.7714\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.5759 - accuracy: 0.8357 - val_loss: 1.0808 - val_accuracy: 0.7714\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.5493 - accuracy: 0.8357 - val_loss: 1.0480 - val_accuracy: 0.8000\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.5450 - accuracy: 0.8429 - val_loss: 1.0806 - val_accuracy: 0.7714\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.5381 - accuracy: 0.8500 - val_loss: 1.0874 - val_accuracy: 0.7714\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.5327 - accuracy: 0.8643 - val_loss: 1.1166 - val_accuracy: 0.7714\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5318 - accuracy: 0.8429 - val_loss: 1.1298 - val_accuracy: 0.7714\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5246 - accuracy: 0.8643 - val_loss: 1.1050 - val_accuracy: 0.7429\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.5216 - accuracy: 0.8571 - val_loss: 1.0870 - val_accuracy: 0.7429\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.5208 - accuracy: 0.8500 - val_loss: 1.1172 - val_accuracy: 0.8000\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.5182 - accuracy: 0.8500 - val_loss: 1.1852 - val_accuracy: 0.7143\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.5206 - accuracy: 0.8571 - val_loss: 1.1262 - val_accuracy: 0.7429\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.5149 - accuracy: 0.8571 - val_loss: 1.0762 - val_accuracy: 0.7714\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5151 - accuracy: 0.8643 - val_loss: 1.1102 - val_accuracy: 0.8000\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.5046 - accuracy: 0.8786 - val_loss: 1.1739 - val_accuracy: 0.7714\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 79ms/step - loss: 0.4943 - accuracy: 0.8643 - val_loss: 1.1627 - val_accuracy: 0.7429\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.5073 - accuracy: 0.8571 - val_loss: 1.1489 - val_accuracy: 0.7714\n",
      "Epoch 115/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4877 - accuracy: 0.8571 - val_loss: 1.1946 - val_accuracy: 0.7429\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4911 - accuracy: 0.8786 - val_loss: 1.1426 - val_accuracy: 0.7714\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4843 - accuracy: 0.8643 - val_loss: 1.1289 - val_accuracy: 0.7714\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4778 - accuracy: 0.8643 - val_loss: 1.2204 - val_accuracy: 0.7143\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.4803 - accuracy: 0.8500 - val_loss: 1.1946 - val_accuracy: 0.7429\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4713 - accuracy: 0.8643 - val_loss: 1.1333 - val_accuracy: 0.8000\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4652 - accuracy: 0.8786 - val_loss: 1.1700 - val_accuracy: 0.7714\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4739 - accuracy: 0.9071 - val_loss: 1.1703 - val_accuracy: 0.7714\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4655 - accuracy: 0.8857 - val_loss: 1.1741 - val_accuracy: 0.8286\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.4674 - accuracy: 0.8643 - val_loss: 1.1450 - val_accuracy: 0.7429\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4626 - accuracy: 0.8643 - val_loss: 1.2020 - val_accuracy: 0.7429\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4594 - accuracy: 0.8786 - val_loss: 1.2551 - val_accuracy: 0.7429\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4682 - accuracy: 0.8571 - val_loss: 1.2771 - val_accuracy: 0.8000\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4556 - accuracy: 0.8643 - val_loss: 1.2386 - val_accuracy: 0.8000\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4525 - accuracy: 0.8714 - val_loss: 1.1599 - val_accuracy: 0.7714\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.4470 - accuracy: 0.8714 - val_loss: 1.1546 - val_accuracy: 0.7714\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4446 - accuracy: 0.8857 - val_loss: 1.2129 - val_accuracy: 0.8000\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.4374 - accuracy: 0.8857 - val_loss: 1.2080 - val_accuracy: 0.7714\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 57ms/step - loss: 0.4380 - accuracy: 0.8786 - val_loss: 1.1897 - val_accuracy: 0.7714\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.4330 - accuracy: 0.8714 - val_loss: 1.1995 - val_accuracy: 0.8000\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.4359 - accuracy: 0.8643 - val_loss: 1.2423 - val_accuracy: 0.7429\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 61ms/step - loss: 0.4252 - accuracy: 0.9000 - val_loss: 1.3102 - val_accuracy: 0.7429\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.4398 - accuracy: 0.8786 - val_loss: 1.2124 - val_accuracy: 0.7714\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4265 - accuracy: 0.8857 - val_loss: 1.1692 - val_accuracy: 0.8000\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.4246 - accuracy: 0.8643 - val_loss: 1.2282 - val_accuracy: 0.8000\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.4243 - accuracy: 0.8857 - val_loss: 1.2607 - val_accuracy: 0.7714\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4154 - accuracy: 0.8929 - val_loss: 1.2121 - val_accuracy: 0.7714\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4071 - accuracy: 0.8857 - val_loss: 1.2039 - val_accuracy: 0.8000\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.4040 - accuracy: 0.9071 - val_loss: 1.2335 - val_accuracy: 0.7714\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.4130 - accuracy: 0.9000 - val_loss: 1.2332 - val_accuracy: 0.8286\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.4130 - accuracy: 0.8643 - val_loss: 1.2081 - val_accuracy: 0.8000\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 83ms/step - loss: 0.3984 - accuracy: 0.8857 - val_loss: 1.2049 - val_accuracy: 0.7714\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.4050 - accuracy: 0.9071 - val_loss: 1.2512 - val_accuracy: 0.8000\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3950 - accuracy: 0.8857 - val_loss: 1.3109 - val_accuracy: 0.7429\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3996 - accuracy: 0.8857 - val_loss: 1.3252 - val_accuracy: 0.7143\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3942 - accuracy: 0.8929 - val_loss: 1.2380 - val_accuracy: 0.8000\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3900 - accuracy: 0.9000 - val_loss: 1.2275 - val_accuracy: 0.8286\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3878 - accuracy: 0.8714 - val_loss: 1.2849 - val_accuracy: 0.8000\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3916 - accuracy: 0.8714 - val_loss: 1.2837 - val_accuracy: 0.7714\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3862 - accuracy: 0.9071 - val_loss: 1.2947 - val_accuracy: 0.8000\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3823 - accuracy: 0.9071 - val_loss: 1.3526 - val_accuracy: 0.7714\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3807 - accuracy: 0.9071 - val_loss: 1.3752 - val_accuracy: 0.7714\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.3792 - accuracy: 0.9071 - val_loss: 1.2754 - val_accuracy: 0.7714\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3741 - accuracy: 0.9000 - val_loss: 1.3155 - val_accuracy: 0.8286\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3705 - accuracy: 0.8929 - val_loss: 1.3000 - val_accuracy: 0.8000\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3811 - accuracy: 0.8714 - val_loss: 1.2609 - val_accuracy: 0.8286\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.3705 - accuracy: 0.8929 - val_loss: 1.2746 - val_accuracy: 0.8000\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3745 - accuracy: 0.9000 - val_loss: 1.1939 - val_accuracy: 0.8000\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 54ms/step - loss: 0.3760 - accuracy: 0.9071 - val_loss: 1.2738 - val_accuracy: 0.7714\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3740 - accuracy: 0.8857 - val_loss: 1.4140 - val_accuracy: 0.7714\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 65ms/step - loss: 0.3623 - accuracy: 0.9071 - val_loss: 1.3467 - val_accuracy: 0.7714\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3678 - accuracy: 0.8857 - val_loss: 1.3346 - val_accuracy: 0.8000\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 60ms/step - loss: 0.3647 - accuracy: 0.8857 - val_loss: 1.2682 - val_accuracy: 0.8286\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3731 - accuracy: 0.8786 - val_loss: 1.2696 - val_accuracy: 0.8286\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 0.3597 - accuracy: 0.9143 - val_loss: 1.3498 - val_accuracy: 0.7429\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3597 - accuracy: 0.8929 - val_loss: 1.4973 - val_accuracy: 0.7429\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.3640 - accuracy: 0.8786 - val_loss: 1.4227 - val_accuracy: 0.7714\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.3564 - accuracy: 0.9000 - val_loss: 1.2949 - val_accuracy: 0.8000\n",
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3550 - accuracy: 0.8929 - val_loss: 1.3502 - val_accuracy: 0.8000\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 82ms/step - loss: 0.3519 - accuracy: 0.9000 - val_loss: 1.3609 - val_accuracy: 0.7714\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 67ms/step - loss: 0.3487 - accuracy: 0.8929 - val_loss: 1.3557 - val_accuracy: 0.8286\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 53ms/step - loss: 0.3453 - accuracy: 0.8929 - val_loss: 1.3503 - val_accuracy: 0.8000\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.3393 - accuracy: 0.9000 - val_loss: 1.3687 - val_accuracy: 0.8286\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.3446 - accuracy: 0.8929 - val_loss: 1.3460 - val_accuracy: 0.8286\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3372 - accuracy: 0.9143 - val_loss: 1.3883 - val_accuracy: 0.8000\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3442 - accuracy: 0.9000 - val_loss: 1.4509 - val_accuracy: 0.7714\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.3547 - accuracy: 0.9071 - val_loss: 1.3471 - val_accuracy: 0.8571\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.3305 - accuracy: 0.9143 - val_loss: 1.3327 - val_accuracy: 0.8286\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 46ms/step - loss: 0.3453 - accuracy: 0.8857 - val_loss: 1.3395 - val_accuracy: 0.8286\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 59ms/step - loss: 0.3327 - accuracy: 0.8929 - val_loss: 1.4510 - val_accuracy: 0.7714\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3340 - accuracy: 0.9000 - val_loss: 1.4731 - val_accuracy: 0.8000\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3344 - accuracy: 0.8929 - val_loss: 1.4496 - val_accuracy: 0.8000\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3269 - accuracy: 0.8786 - val_loss: 1.3782 - val_accuracy: 0.8000\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3504 - accuracy: 0.8857 - val_loss: 1.4327 - val_accuracy: 0.7714\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.3319 - accuracy: 0.8786 - val_loss: 1.4922 - val_accuracy: 0.7714\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3261 - accuracy: 0.9071 - val_loss: 1.3720 - val_accuracy: 0.8286\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3210 - accuracy: 0.9214 - val_loss: 1.3684 - val_accuracy: 0.8000\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 56ms/step - loss: 0.3271 - accuracy: 0.8929 - val_loss: 1.3575 - val_accuracy: 0.8286\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.3142 - accuracy: 0.9214 - val_loss: 1.4642 - val_accuracy: 0.7714\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.3316 - accuracy: 0.8929 - val_loss: 1.4158 - val_accuracy: 0.8000\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.3222 - accuracy: 0.9214 - val_loss: 1.3806 - val_accuracy: 0.8571\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3152 - accuracy: 0.9000 - val_loss: 1.4973 - val_accuracy: 0.8000\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3140 - accuracy: 0.9000 - val_loss: 1.4180 - val_accuracy: 0.8000\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 58ms/step - loss: 0.3035 - accuracy: 0.9143 - val_loss: 1.3490 - val_accuracy: 0.8000\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 51ms/step - loss: 0.3166 - accuracy: 0.9214 - val_loss: 1.3793 - val_accuracy: 0.8286\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.3032 - accuracy: 0.9143 - val_loss: 1.5060 - val_accuracy: 0.8000\n",
      "2/2 [==============================] - 0s 20ms/step - loss: 1.5060 - accuracy: 0.8000\n",
      "Validation Loss: 1.5059890747070312, Validation Accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_left_train, X_right_train, X_pose_train], y_train, epochs=200, batch_size=32,\n",
    "                    validation_data=([X_left_val, X_right_val, X_pose_val], y_val))\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate([X_left_val, X_right_val, X_pose_val], y_val)\n",
    "print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model\n",
    "model.save('Models/sign_language_letter_model_2.h5')\n",
    "# model.save('Models/sign_language_word_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
