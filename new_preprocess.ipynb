{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyarrow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcsv\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_left_hand_index = 20\n",
    "max_right_hand_index = 20\n",
    "max_pose_index = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_hand_columns = [f\"left_hand_{i}\" for i in range(max_left_hand_index + 1)]\n",
    "right_hand_columns = [f\"right_hand_{i}\" for i in range(max_right_hand_index + 1)]\n",
    "pose_columns = [f\"pose_{i}\" for i in range(max_pose_index + 1)]\n",
    "\n",
    "\n",
    "# Combine all column headers into a single list\n",
    "all_columns = [f\"{col}_{coord}\" for col in left_hand_columns for coord in ['x', 'y','z']] + \\\n",
    "              [f\"{col}_{coord}\" for col in right_hand_columns for coord in ['x', 'y','z']] + \\\n",
    "              [f\"{col}_{coord}\" for col in pose_columns for coord in ['x', 'y','z']] + \\\n",
    "              ['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Dataset_CSVs/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_words = [\"TV\", \"after\",  \"all\", \"alligator\", \"animal\", \"another\", \"any\", \"apple\", \"arm\"]\n",
    "# selected_words = [\"TV\", \"after\", \"airplane\", \"all\", \"alligator\"]\n",
    "\n",
    "# Filter the dataframe to include only the selected words\n",
    "filtered_df = train_df[train_df['sign'].isin(selected_words)]\n",
    "\n",
    "# Group by 'sign' and select 10 sequences for each word\n",
    "sub_df = filtered_df.groupby('sign').head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Initialize an empty list to store all rows of data\n",
    "all_rows = []\n",
    "\n",
    "# Iterate through each row in sub_df\n",
    "for index, row in sub_df.iterrows():\n",
    "    path = row['path']\n",
    "    label = row['sign']\n",
    "    \n",
    "    # Read the Parquet file using PyArrow\n",
    "    table = pq.read_table(path)\n",
    "    \n",
    "    # Convert PyArrow Table to Pandas DataFrame\n",
    "    df = table.to_pandas()\n",
    "    \n",
    "    # Initialize a list to store rows of data\n",
    "    rows = []\n",
    "    \n",
    "    # Iterate through each unique frame\n",
    "    for frame in df['frame'].unique():\n",
    "        # Filter rows for the current frame\n",
    "        subset_df = df[df['frame'] == frame]\n",
    "        \n",
    "        # Initialize dictionaries to store landmarks\n",
    "        face_dict = {}\n",
    "        left_hand_dict = {}\n",
    "        right_hand_dict = {}\n",
    "        pose_dict = {}\n",
    "        \n",
    "        # Iterate through rows in subset_df and populate dictionaries\n",
    "        for idx, row in subset_df.iterrows():\n",
    "            landmark_type = row['type']\n",
    "            landmark_index = row['landmark_index']\n",
    "            x = row['x']\n",
    "            y = row['y']\n",
    "            z = row['z']\n",
    "            \n",
    "            if landmark_type == 'left_hand':\n",
    "                left_hand_dict[f\"left_hand_{landmark_index}_x\"] = x\n",
    "                left_hand_dict[f\"left_hand_{landmark_index}_y\"] = y\n",
    "                left_hand_dict[f\"left_hand_{landmark_index}_z\"] = z\n",
    "            elif landmark_type == 'right_hand':\n",
    "                right_hand_dict[f\"right_hand_{landmark_index}_x\"] = x\n",
    "                right_hand_dict[f\"right_hand_{landmark_index}_y\"] = y\n",
    "                right_hand_dict[f\"right_hand_{landmark_index}_z\"] = z\n",
    "            elif landmark_type == 'pose':\n",
    "                pose_dict[f\"pose_{landmark_index}_x\"] = x\n",
    "                pose_dict[f\"pose_{landmark_index}_y\"] = y\n",
    "                pose_dict[f\"pose_{landmark_index}_z\"] = z\n",
    "        \n",
    "        # Combine dictionaries into a single row of data\n",
    "        row_data = {\n",
    "            **left_hand_dict,\n",
    "            **right_hand_dict,\n",
    "            **pose_dict,\n",
    "            'label': label,\n",
    "        }\n",
    "        \n",
    "        # Append row_data to rows list\n",
    "        rows.append(row_data)\n",
    "    \n",
    "    # Extend rows to all_rows\n",
    "    all_rows.extend(rows)\n",
    "\n",
    "# Define CSV file path\n",
    "csv_file = 'Dataset_CSVs/ASL_word_data_xyz.csv'\n",
    "\n",
    "# Define column headers as the union of keys from all row_data dictionaries\n",
    "# header = ['frame'] + sorted(set().union(*(row.keys() for row in all_rows)))\n",
    "\n",
    "# Write rows to CSV file\n",
    "with open(csv_file, 'w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=all_columns)\n",
    "    writer.writeheader()\n",
    "    \n",
    "    # Iterate through all_rows and write each row to CSV\n",
    "    for row_data in all_rows:\n",
    "        # Round numerical values to 3 decimal places\n",
    "        rounded_row_data = {key: round(value, 6) if isinstance(value, (int, float)) else value for key, value in row_data.items()}\n",
    "        \n",
    "        # Replace NaN values with 0.0\n",
    "        cleaned_row_data = {key: (0.0 if pd.isna(value) else value) for key, value in rounded_row_data.items()}\n",
    "        \n",
    "        # Write the row to CSV\n",
    "        writer.writerow(cleaned_row_data)\n",
    "\n",
    "print(f\"Data has been successfully written to {csv_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "# Load the data from the CSV file\n",
    "df = pd.read_csv('Dataset_CSVs/ASL_word_data_xyz.csv')\n",
    "\n",
    "# Define landmark columns\n",
    "left_hand_columns = [f\"left_hand_{i}\" for i in range(21)]\n",
    "right_hand_columns = [f\"right_hand_{i}\" for i in range(21)]\n",
    "pose_columns = [f\"pose_{i}\" for i in range(33)]\n",
    "\n",
    "left_hand_coords = [f\"{col}_{coord}\" for col in left_hand_columns for coord in ['x', 'y', 'z']]\n",
    "right_hand_coords = [f\"{col}_{coord}\" for col in right_hand_columns for coord in ['x', 'y', 'z']]\n",
    "pose_coords = [f\"{col}_{coord}\" for col in pose_columns for coord in ['x', 'y', 'z']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract left hand coordinates and reshape into array\n",
    "left_hand_coords_array = df[left_hand_coords].values.flatten()\n",
    "right_hand_coords_array = df[right_hand_coords].values.flatten()\n",
    "pose_coords_array = df[pose_coords].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_mediapipe_format(coords_array, num_landmarks):\n",
    "    if len(coords_array) != num_landmarks * 3:  # Each landmark has x, y, z\n",
    "        raise ValueError(f\"Input array should contain {num_landmarks * 3} values ({num_landmarks} landmarks * 3 coordinates)\")\n",
    "\n",
    "    mediapipe_landmarks = landmark_pb2.NormalizedLandmarkList()\n",
    "\n",
    "    for i in range(0, len(coords_array), 3):\n",
    "        x, y, z = coords_array[i:i+3]\n",
    "        # Create a new NormalizedLandmark object and assign the x, y, z values\n",
    "        landmark = landmark_pb2.NormalizedLandmark(x=x, y=y, z=z)\n",
    "        # Append the landmark to the list\n",
    "        mediapipe_landmarks.landmark.append(landmark)\n",
    "\n",
    "    return mediapipe_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediapipe_array_lefthand = convert_to_mediapipe_format(left_hand_coords_array, 21) \n",
    "mediapipe_array_righthand = convert_to_mediapipe_format(right_hand_coords_array, 21)  \n",
    "mediapipe_array_pose = convert_to_mediapipe_format(pose_coords_array, 33) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "def visualize_and_save_landmarks(landmarks_dict, connections, filename):\n",
    "    # Initialize MediaPipe drawing utilities\n",
    "    mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "    # Create a blank image (white background)\n",
    "    image = np.ones((480, 640, 3), dtype=np.uint8) * 255\n",
    "\n",
    "    # Draw the landmarks on the image\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image,\n",
    "        landmark_list=landmarks_dict,\n",
    "        connections=connections,\n",
    "        landmark_drawing_spec=mp_drawing.DrawingSpec(color=(0, 0, 255), thickness=1, circle_radius=2),\n",
    "        connection_drawing_spec=mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "    )\n",
    "\n",
    "    # Save the image\n",
    "    cv2.imwrite(filename, image)\n",
    "\n",
    "    # Display the image (optional, you can remove this if you just want to save the images)\n",
    "    cv2.imshow('Landmarks', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_and_save_landmarks(mediapipe_array_lefthand, mp.solutions.hands.HAND_CONNECTIONS, 'left_hand_landmarks.png')\n",
    "visualize_and_save_landmarks(mediapipe_array_righthand, mp.solutions.hands.HAND_CONNECTIONS, 'right_hand_landmarks.png')\n",
    "visualize_and_save_landmarks(mediapipe_array_pose, mp.solutions.pose.POSE_CONNECTIONS, 'pose_landmarks.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
